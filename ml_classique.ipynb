{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation par rapport au dataset est appliquée aux données d'entrainemnet\n",
      "PCA entraînée et appliquée aux données d'entrainement - Nouvelle forme: (97655, 439)\n",
      "Poids de classe calculés [ 0.50433817 58.12797619]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import os \n",
    "from importlib import reload\n",
    "import functions as fct\n",
    "reload(fct)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import metric_seq2seq\n",
    "reload(metric_seq2seq)\n",
    "from metric_seq2seq import PrecisionSeq, RecallSeq, AUCSeq, F1ScoreSeq\n",
    "\n",
    "ind_mf4_train = 4\n",
    "\n",
    "ind_mic = 1\n",
    "sr = 100000\n",
    "tfn = 0.02\n",
    "FMAX = 22000\n",
    "seq2seq = False\n",
    "N_window = fct.get_near_pof2(tfn,sr)\n",
    "NB_FEATURES = 64\n",
    "apply_pca = False\n",
    "    #extraire les coefs mels\n",
    "if True :  \n",
    "    mels ,labels = [],[]\n",
    "    for ind_train,debut,fin in zip([ind_mf4_train],[int(1*60)],[int(17*60+40)]):\n",
    "        xi,yi = fct.fft_features(list_mf4 = [ind_train],\n",
    "                                    list_mics = [ind_mic],\n",
    "                                    N_window = N_window,\n",
    "                                    #nb_mels = NB_FEATURES,\n",
    "                                    #power = 2.0,\n",
    "                                    debut = debut,\n",
    "                                    fin = fin,\n",
    "                                    annot = True,\n",
    "                                    sous_mean = True,\n",
    "                                    feature = \"audio\",\n",
    "                                    f_max = FMAX,\n",
    "                                    overlap = 2, #25% de hop_lenght pour le calule des mels\n",
    "                                    #energie = \"both\",\n",
    "                                    precoce = True,\n",
    "                                    #derive1 = False,\n",
    "                                    #derive2 = False,\n",
    "                                    \n",
    "                                    nbr_classes= 2 )\n",
    "        mels.append(xi)\n",
    "        labels.append(yi)\n",
    "\n",
    "\n",
    "    X,Y = [],[]\n",
    "    X_val,Y_val = [],[]\n",
    "    X_test,Y_test = [],[]\n",
    "\n",
    "    for key in mels[0].keys():\n",
    "        X,Y = np.array(mels[0][key]),np.array(labels[0][key])\n",
    "\n",
    "\n",
    "    #prétraitement des donnees\n",
    "    X,Y,class_weights,pca,scaler = fct.pretrait(X,Y,n_components=0.95,\n",
    "                                                apply_norm=True,\n",
    "                                                seq=False,\n",
    "                                                seq2seq=seq2seq,\n",
    "                                                seq_apres=10,\n",
    "                                                seq_before=9,\n",
    "                                                apply_pca=True,\n",
    "                                                overlap=0.5,\n",
    "                                                super_vecteur=False\n",
    "                                                )\n",
    "\n",
    "\n",
    "    X_train,X_val,Y_train,Y_val = train_test_split(X,Y,stratify=Y,test_size=0.4,random_state=0)\n",
    "    X_val,X_test,Y_val,Y_test = train_test_split(X_val,Y_val,stratify=Y_val,random_state=0,test_size=0.5)\n",
    "\n",
    "weights = np.ones(Y_train.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(Y_train):\n",
    "    weights[i] = class_weights[val-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b2b9843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58593, 439)\n",
      "[58089   504]\n"
     ]
    }
   ],
   "source": [
    "Xt = X_train[:,:]\n",
    "Xv = X_val[:,:]\n",
    "print(Xt.shape)\n",
    "print(np.bincount(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968523d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Création du vecteur de poids\n",
    "weights = np.ones(Y_train.shape[0], dtype='float')\n",
    "for i, val in enumerate(Y_train):\n",
    "    weights[i] = class_weights[val - 1]\n",
    "\n",
    "# Fonction objectif\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [50,100,500]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [3,5,7,9,11]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.5,0.7,1.0]),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5,0.7,1]),\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': 0\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, Y_train, sample_weight=weights)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1_class1 = f1_score(Y_test, y_pred, pos_label=1)\n",
    "\n",
    "    # Affichage pour chaque trial\n",
    "    print(f\"Trial {trial.number} - F1 (classe 1): {f1_class1:.4f} | Params: {params}\")\n",
    "\n",
    "    return f1_class1\n",
    "\n",
    "# Lancer l’étude Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c8625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extrait sauvegardé dans extrait_3_4_33.wav\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "def decouper_audio(path_in, path_out, start_sec, end_sec):\n",
    "    \"\"\"\n",
    "    Découpe un extrait d'un fichier audio et l'enregistre dans un nouveau fichier.\n",
    "    \n",
    "    :param path_in: chemin du fichier audio d'entrée (.wav, .mp3, etc.)\n",
    "    :param path_out: chemin du nouveau fichier audio de sortie (.wav de préférence)\n",
    "    :param start_sec: début de l'extrait en secondes\n",
    "    :param end_sec: fin de l'extrait en secondes\n",
    "    \"\"\"\n",
    "    # Charger l'audio (en mono)\n",
    "    y, sr = librosa.load(path_in, sr=100000)\n",
    "    \n",
    "    # Convertir secondes en indices\n",
    "    start_sample = int(start_sec * sr)\n",
    "    end_sample = int(end_sec * sr)\n",
    "    \n",
    "    # Vérification des bornes\n",
    "    if start_sample < 0 or end_sample > len(y) or start_sample >= end_sample:\n",
    "        raise ValueError(\"Plage temporelle invalide.\")\n",
    "    \n",
    "    # Extraire l'extrait\n",
    "    extrait = y[start_sample:end_sample]\n",
    "    \n",
    "    # Sauvegarder dans un nouveau fichier WAV\n",
    "    sf.write(path_out, extrait, sr)\n",
    "    print(f\"✅ Extrait sauvegardé dans {path_out}\")\n",
    "\n",
    "path_in =  os.path.join(\"data\",\"audios\",\"Son_3_4.wav\")          #\"C:\\\\Users\\\\mohammed-amine.tanna\\\\OneDrive - RAILENIUM\\\\Bureau\\\\stage_railenium\\\\Telli\\\\Revigny\\\\data\\\\audios\\\\Son_4_1.wav\"\n",
    "path_out = \"extrait_3_4_33.wav\"\n",
    "start_sec = int(2*60+35)               #int(6*60+7)           int(7*60 + 37)   \n",
    "end_sec =   int(9*60+24)              #int(8*60+10)          int(10*60+37)\n",
    "decouper_audio(path_in=path_in,path_out=path_out,start_sec=start_sec,end_sec=end_sec)   #5 joints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fft_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
