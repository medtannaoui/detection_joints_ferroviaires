{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966499d4",
   "metadata": {},
   "source": [
    "## Test des modeles (cm,roc,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b502068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_txt(lst, filename):\n",
    "    # Sauvegarde directement les valeurs (sans normaliser)\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for value in lst:\n",
    "            f.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82784d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\fusion\\acc134_aud1234.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohammed-amine.tanna\\AppData\\Local\\anaconda3\\envs\\fft_env\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from importlib import reload\n",
    "import metric_seq2seq\n",
    "reload(metric_seq2seq)\n",
    "from metric_seq2seq import *\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "#choix du modéle utilisé\n",
    "mic = \"12\"         #le microphone souhaité à tester\n",
    "feature = \"audio\"\n",
    "dossier = \"acceleros\" if feature == \"acc\" else \"audios\"\n",
    "file = f\"{feature}_{mic}.pkl\"\n",
    "dossier = \"fusion\"\n",
    "file = \"acc134_aud1234.pkl\"\n",
    "file_donnees = os.path.join(\"models\",dossier,file)\n",
    "\n",
    "print(file_donnees)\n",
    "with open(file_donnees, \"rb\") as f:\n",
    "    data0 = pickle.load(f)\n",
    "\n",
    "f1s = []\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    y_true_data , y_pred_data = data0[i]\n",
    "    y_true = y_true_data.argmax(axis=-1).flatten()\n",
    "    y_pred = (y_pred_data[:,1] > 0.5).astype(int)\n",
    "    y_true_all.append(y_true)\n",
    "    y_pred_all.append(y_pred)\n",
    "    f1s.append(f1_score(y_true, y_pred, average=\"binary\", pos_label=1))\n",
    "\n",
    "'''plt.figure(figsize=(15,8))\n",
    "plt.step(range(len(y_true)),y_true,label=\"true\")\n",
    "plt.step(range(len(y_true)),y_pred,label=\"pred\",linestyle=\"--\")\n",
    "\n",
    "#plt.step(range(len(y_true)),y_pred_data[:,1],label=\"pred\")\n",
    "plt.legend()\n",
    "plt.show()'''\n",
    "\n",
    "sets = [\"Train\", \"Val\", \"Test\"]\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "if True:\n",
    "    cm = confusion_matrix(y_true_all[1], y_pred_all[1])\n",
    "    cm_normalized = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Création des annotations : \"xx.xx%\\n(nb)\"\n",
    "    annotations = np.empty_like(cm, dtype=object)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            annotations[i, j] = f\"{cm_normalized[i, j]*100:.2f}%\\n({cm[i, j]})\"\n",
    "\n",
    "    sns.heatmap(cm_normalized, annot=annotations, fmt=\"\", cmap=\"Blues\")\n",
    "    plt.title(f\"{sets[2]} Confusion Matrix des données de test {mic}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "history = data0[3][2]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "metrics = [\"loss\", \"f1_class_1\", \"auc_binary\"]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i ==1 and j ==1 :\n",
    "            break\n",
    "        metric = metrics[i * 2 + j]  \n",
    "        \n",
    "        axes[i, j].plot(history[metric], label=\"train\")\n",
    "        axes[i, j].plot(history[f\"val_{metric}\"], label=\"val\")\n",
    "        \n",
    "        axes[i, j].set_title(metric)\n",
    "        axes[i, j].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822fdd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.bar([\"train\",\"val\",\"test\"], f1s, color=[\"skyblue\",\"orange\",\"green\"])\n",
    "plt.title(\"F1 Score\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sets = [\"Train\", \"Val\", \"Test\"]\n",
    "\n",
    "if True:\n",
    "    cm = confusion_matrix(y_true_all[1], y_pred_all[1])\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "    plt.title(f\"{sets[2]} Confusion Matrix des données de test {mic}'\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "for i in range(3):\n",
    "    y_true = y_true_all[i]\n",
    "    y_pred = y_pred_all[i]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{sets[i]} AUC={roc_auc:.2f}\")\n",
    "\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curves micro {mic}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "history = data0[3][2]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "metrics = [\"loss\", \"f1_class_1\", \"auc_binary\"]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i ==1 and j ==1 :\n",
    "            break\n",
    "        metric = metrics[i * 2 + j]  \n",
    "        \n",
    "        axes[i, j].plot(history[metric], label=\"train\")\n",
    "        axes[i, j].plot(history[f\"val_{metric}\"], label=\"val\")\n",
    "        \n",
    "        axes[i, j].set_title(metric)\n",
    "        axes[i, j].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adbc7b0",
   "metadata": {},
   "source": [
    "## Prediction sur les données d'aller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cea8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from metric_seq2seq import AUCSeq, F1ScoreSeq, PrecisionSeq, RecallSeq\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "custom_objects = {\n",
    "    \"AUCSeq\": AUCSeq,\n",
    "    \"F1ScoreSeq\": F1ScoreSeq,\n",
    "    \"PrecisionSeq\": PrecisionSeq,\n",
    "    \"RecallSeq\": RecallSeq\n",
    "}\n",
    "\n",
    "dossier = \"audios\"\n",
    "file = f'{\"audio\"}_{12}'\n",
    "'''file = f'acc34_aud12'\n",
    "dossier = \"fusion\"'''\n",
    "model_file = os.path.join('models',dossier,file+'.keras')\n",
    "model = load_model(\n",
    "    model_file,\n",
    "    custom_objects=custom_objects,compile=False\n",
    ")\n",
    "\n",
    "data_model_pkl = os.path.join('models',dossier,file+'.pkl')\n",
    "with open(data_model_pkl,\"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "scaler = data[3][1]\n",
    "print(type(scaler))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767fa1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation par rapport au dataset est appliquée aux données de validation\n",
      "8343 séquences créées avec un chevauchement de 50.0%.\n",
      "Forme après création de séquences : (8343, 20, 388)\n",
      "Poids de classe calculés [0.52657157 9.90855107]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import os \n",
    "from importlib import reload\n",
    "import functions as fct\n",
    "reload(fct)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import metric_seq2seq\n",
    "reload(metric_seq2seq)\n",
    "from metric_seq2seq import PrecisionSeq, RecallSeq, AUCSeq, F1ScoreSeq\n",
    "\n",
    "debuts , fins = int(1*60+00),int(17*60+40)          # debut et fin en secondes\n",
    "mf4 = 3\n",
    "total = False\n",
    "sr = 100000\n",
    "tfn = 0.02\n",
    "FMAX = 22000\n",
    "seq2seq = False\n",
    "N_window = fct.get_near_pof2(tfn,sr)\n",
    "NB_FEATURES = 64\n",
    "apply_pca = False\n",
    "    #extraire les coefs mels\n",
    "if True:  \n",
    "    mels ,labels = [],[]\n",
    "    for ind_train,debut,fin in zip([mf4],[debuts],[fins]):\n",
    "        if  not total:\n",
    "            xi,yi = fct.mels_features(list_mf4 = [ind_train],\n",
    "                                        list_mics = [1,2],\n",
    "                                        N_window = N_window,\n",
    "                                        nb_mels = NB_FEATURES,\n",
    "                                        power = 2.0,\n",
    "                                        debut = debut,\n",
    "                                        fin = fin,\n",
    "                                        annot = True,\n",
    "                                        sous_mean = True,\n",
    "                                        feature = \"audio\",\n",
    "                                        f_max = FMAX,\n",
    "                                        overlap = 2, #25% de hop_lenght pour le calule des mels\n",
    "                                        energie = \"both\",\n",
    "                                        precoce = True,\n",
    "                                        derive1 =True,\n",
    "                                        derive2 = True,\n",
    "                                        \n",
    "                                        nbr_classes= 2 )\n",
    "        \n",
    "            \n",
    "        elif total :\n",
    "            mels ,labels = [],[] \n",
    "            for ind_train,debut,fin in zip([mf4],[debuts],[fins]):    #zip([ind_mf4_train],[int(1*60)],[int(17*60+40)])\n",
    "                xi,yi = fct.mels_features(list_mf4 = [ind_train],\n",
    "                                            list_mics = [1,2],\n",
    "                                            N_window = N_window,\n",
    "                                            debut = debut,\n",
    "                                            fin = fin,\n",
    "                                            annot = True,\n",
    "                                            sous_mean = True,\n",
    "                                            feature = \"audio\",\n",
    "                                            f_max = 22000,\n",
    "                                            overlap = 2, \n",
    "                                            energie = \"both\",\n",
    "                                            precoce = True,\n",
    "                                            power=2.0,\n",
    "                                            nb_mels=64,\n",
    "                                            derive1=True,\n",
    "                                            derive2=False,\n",
    "                                            nbr_classes= 2  )\n",
    "                mels.append(xi)\n",
    "                labels.append(yi)\n",
    "            \n",
    "            for ind_train,debut,fin in zip([mf4],[debuts],[fins]):    #zip([ind_mf4_train],[int(1*60)],[int(17*60+40)])\n",
    "                xi,yi = fct.mels_features(list_mf4 = [ind_train],\n",
    "                                            list_mics = [3],\n",
    "                                            N_window = N_window,\n",
    "                                            debut = debut,\n",
    "                                            fin = fin,\n",
    "                                            annot = True,\n",
    "                                            sous_mean = True,\n",
    "                                            feature = \"acc\",\n",
    "                                            f_max = 10000,\n",
    "                                            overlap = 2, \n",
    "                                            energie = \"both\",\n",
    "                                            precoce = True,\n",
    "                                            power=2.0,\n",
    "                                            nb_mels=64,\n",
    "                                            derive1=True,\n",
    "                                            derive2=False,                                                                                       \n",
    "                                            nbr_classes= 2 )\n",
    "                mels.append(xi)\n",
    "                labels.append(yi)\n",
    "\n",
    "\n",
    "            X,Y = [],[]\n",
    "            X_val,Y_val = [],[]\n",
    "            X_test,Y_test = [],[]\n",
    "\n",
    "            for key in mels[0].keys():\n",
    "                X,Y = np.array(mels[0][key]) , np.array(labels[0][key])\n",
    "            for key in mels[1].keys():\n",
    "                X,Y = np.concatenate((X,mels[1][key]),axis=1),Y\n",
    "            \n",
    "\n",
    "            print(f\"shape des données est {X.shape} et la distribution des classes esr {np.bincount(Y)}\")\n",
    "\n",
    "\n",
    "        if not total : \n",
    "            mels.append(xi)\n",
    "            labels.append(yi)\n",
    "\n",
    "\n",
    "            X,Y = [],[]\n",
    "            X_val,Y_val = [],[]\n",
    "            X_test,Y_test = [],[]\n",
    "\n",
    "            for key in mels[0].keys():\n",
    "                X,Y = np.array(mels[0][key]),np.array(labels[0][key])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #prétraitement des donnees\n",
    "    X,Y,_,_,_ = fct.pretrait(X,Y,n_components=0.95,\n",
    "                                                apply_norm=True,\n",
    "                                                seq=True,\n",
    "                                                seq2seq=seq2seq,\n",
    "                                                seq_apres= 10,\n",
    "                                                seq_before= 9,\n",
    "                                                apply_pca=apply_pca,\n",
    "                                                overlap= 0.5,\n",
    "                                                super_vecteur=False,\n",
    "                                                scaler=scaler\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46377223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 953ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X)\n",
    "y_pred = y_pred_proba.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4491e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "yp_probas = y_pred_proba[:,1]\n",
    "'''list_to_txt(yp_probas,\"pred.txt\")\n",
    "list_to_txt(Y,\"true.txt\")'''\n",
    "y_pred =(yp_probas > 0.38).astype(int)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.step(range(len(Y)), Y, label=\"true\")\n",
    "#plt.step(range(len(Y)), y_pred, label=\"pred\", linestyle='--')\n",
    "plt.step(range(len(Y)), y_pred_proba[:,1], label=\"pred\", linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca079b7f",
   "metadata": {},
   "source": [
    "## Faire des comparaison entre differents models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e187332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohammed-amine.tanna\\AppData\\Local\\anaconda3\\envs\\fft_env\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nfig , axes = plt.subplots(1,len(datas),figsize=(20,5))\\nfor  data , axe , i in zip([*datas],axes,range(len(datas))) : \\n    cm = confusion_matrix(data[2][0].argmax(axis=1) , data[2][1].argmax(axis=1))\\n    sns.heatmap(cm/cm.sum(axis=1,keepdims=True), annot=True,cmap=\\'Blues\\', ax=axe)\\n    axe.set_title(f\"Model {models_name[i]}\")\\n    axe.set_xlabel(\\'Prédiction\\')\\n    axe.set_ylabel(\\'Réel\\')\\n\\nmodel_names = [f\"Model {i}\" for i in range(len(datas))]\\nset_names = [\\'Train\\', \\'Validation\\', \\'Test\\']\\nset_indices = [0, 1, 2]\\n\\n# Créer les sous-figures\\nfig, axes = plt.subplots(1, len(datas), figsize=(20, 5))\\n\\n# Boucle sur les modèles et les axes\\nfor data, axe, model_name in zip([*datas], axes, model_names):\\n    # Pour chaque ensemble (train, val, test)\\n    for idx, set_name in zip(set_indices, set_names):\\n        y_true = data[idx][0].argmax(axis=1)\\n        y_score = data[idx][1][:, 1]  # Probabilité de la classe 1\\n        fpr, tpr, _ = roc_curve(y_true, y_score)\\n        roc_auc = auc(fpr, tpr)\\n\\n        axe.plot(fpr, tpr, label=f\"{set_name} AUC = {roc_auc:.2f}\")\\n\\n    axe.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\\n    axe.set_xlabel(\"False Positive Rate\")\\n    axe.set_ylabel(\"True Positive Rate\")\\n    axe.set_title(f\"ROC Curve - {model_name}\")\\n    axe.legend()\\n\\nplt.tight_layout()\\nplt.show()\\n\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "import os\n",
    "\n",
    "\n",
    "# Charger les fichiers pickle\n",
    "models_name = [\"audio_1\",\"audio_2\",\"acc_3\",\"audio_12\",\"acc_34\",\"acc3_aud12\",\"acc134_aud1234\"]        #indices des modeles à comparer (12 : microphones 1 et 2 )\n",
    "dossiers = [\"audios\",\"audios\",\"acceleros\",\"audios\",\"acceleros\",\"fusion\",\"fusion\"]\n",
    "datas = []\n",
    "files = []\n",
    "for i,mic in enumerate(models_name) : \n",
    "    files.append(os.path.join('models',dossiers[i],f'{mic}.pkl'))\n",
    "\n",
    "for i in range(len(models_name)) : \n",
    "    with open(files[i],\"rb\") as f : \n",
    "        datas.append(pickle.load(f))\n",
    "\n",
    "\n",
    "# Fonction pour calculer le F1 score pour chaque ensemble\n",
    "def compute_f1(data):\n",
    "    sets = ['train', 'val', 'test']\n",
    "    f1s = []\n",
    "    for i, name in enumerate(sets):\n",
    "        y_true = data[i][0].argmax(axis=1)\n",
    "        y_pred = (data[i][1][:,1] > 0.5).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"binary\", pos_label=1)\n",
    "        f1s.append((name, f1))\n",
    "    return f1s\n",
    "\n",
    "# Récupérer les scores\n",
    "scores = []\n",
    "for data in datas : \n",
    "    scores.append(compute_f1(data))\n",
    "\n",
    "\n",
    "# Mettre les résultats dans un DataFrame\n",
    "all_data = []\n",
    "\n",
    "for model_name, scores in zip(\n",
    "    [f\"Model {i}\" for i in models_name], \n",
    "    [*scores]\n",
    "):\n",
    "    for set_name, f1 in scores:\n",
    "        all_data.append({'Model': model_name, 'Set': set_name, 'F1-score': f1})\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Tracer le graphique\n",
    "plt.figure(figsize=(14,8))\n",
    "sns.barplot(data=df, x='Set', y='F1-score', hue='Model')\n",
    "plt.title('F1-score de la classe joint')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "fig , axes = plt.subplots(1,len(datas),figsize=(20,5))\n",
    "for  data , axe , i in zip([*datas],axes,range(len(datas))) : \n",
    "    cm = confusion_matrix(data[2][0].argmax(axis=1) , data[2][1].argmax(axis=1))\n",
    "    sns.heatmap(cm/cm.sum(axis=1,keepdims=True), annot=True,cmap='Blues', ax=axe)\n",
    "    axe.set_title(f\"Model {models_name[i]}\")\n",
    "    axe.set_xlabel('Prédiction')\n",
    "    axe.set_ylabel('Réel')\n",
    "\n",
    "model_names = [f\"Model {i}\" for i in range(len(datas))]\n",
    "set_names = ['Train', 'Validation', 'Test']\n",
    "set_indices = [0, 1, 2]\n",
    "\n",
    "# Créer les sous-figures\n",
    "fig, axes = plt.subplots(1, len(datas), figsize=(20, 5))\n",
    "\n",
    "# Boucle sur les modèles et les axes\n",
    "for data, axe, model_name in zip([*datas], axes, model_names):\n",
    "    # Pour chaque ensemble (train, val, test)\n",
    "    for idx, set_name in zip(set_indices, set_names):\n",
    "        y_true = data[idx][0].argmax(axis=1)\n",
    "        y_score = data[idx][1][:, 1]  # Probabilité de la classe 1\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        axe.plot(fpr, tpr, label=f\"{set_name} AUC = {roc_auc:.2f}\")\n",
    "\n",
    "    axe.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
    "    axe.set_xlabel(\"False Positive Rate\")\n",
    "    axe.set_ylabel(\"True Positive Rate\")\n",
    "    axe.set_title(f\"ROC Curve - {model_name}\")\n",
    "    axe.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8762b4",
   "metadata": {},
   "source": [
    "## Prediction par rapport au motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20ba5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Données brutes\n",
    "TP = 41                              #45\n",
    "FN = 10\n",
    "FP = 1\n",
    "TN = 1000  \n",
    "\n",
    "# Matrice brute\n",
    "cm = np.array([[TP, FN],\n",
    "               [FP, TN]])\n",
    "\n",
    "# Pourcentages par ligne\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Labels : valeur + pourcentage\n",
    "labels = np.array([[f\"{val}\\n({pct:.1f}%)\" if not np.isnan(pct) else f\"{val}\\n(N/A)\"\n",
    "                    for val, pct in zip(row_val, row_pct)]\n",
    "                   for row_val, row_pct in zip(cm, cm_percent)])\n",
    "\n",
    "# Affichage avec les couleurs selon les pourcentages\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cm_percent, annot=labels, fmt=\"\", cmap=\"Blues\", cbar=True,\n",
    "            xticklabels=[\"Prédit : Joint\", \"Prédit : Pas joint\"],\n",
    "            yticklabels=[\"Réel : Joint\", \"Réel : Pas joint\"],\n",
    "            vmin=0, vmax=100)  # 0% à 100%\n",
    "\n",
    "plt.title(\"Matrice de confusion (motifs) (seuil 0.38)\")\n",
    "plt.ylabel(\"Réel\")\n",
    "plt.xlabel(\"Prédit\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fft_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
